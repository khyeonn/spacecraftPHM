{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b6b817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f44c57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_dict = {}\n",
    "Testing_dict = {}\n",
    "\n",
    "for file in sorted(os.listdir(r\"/Users/matthewweiner/Downloads/dataset/test/data\")):\n",
    "     Testing_dict[file] = pd.read_csv(r\"/Users/matthewweiner/Downloads/dataset/test/data/\" + file, header = 0, sep = ',', nrows=100)\n",
    "    \n",
    "    \n",
    "for file in sorted(os.listdir(r\"/Users/matthewweiner/Downloads/dataset/train/data\")):\n",
    "    Training_dict[file] = pd.read_csv(r\"/Users/matthewweiner/Downloads/dataset/train/data/\" + file, header = 0, sep = ',', nrows=100)\n",
    "    \n",
    "# Read Labels for test set \n",
    "test_label = pd.read_excel(r\"/Users/matthewweiner/Downloads/dataset/test/labels_spacecraft.xlsx\", header = 1)\n",
    "\n",
    "# Read Labels for training set \n",
    "train_label = pd.read_excel(r\"/Users/matthewweiner/Downloads/dataset/train/labels.xlsx\", header = 1)\n",
    "\n",
    "training_keys = sorted(os.listdir(r\"/Users/matthewweiner/Downloads/dataset/train/data\"))\n",
    "testing_keys = sorted(os.listdir(r\"/Users/matthewweiner/Downloads/dataset/test/data\"))\n",
    "\n",
    "answers = pd.read_csv(r\"/Users/matthewweiner/Downloads/test data/answer.csv\", header = 0, sep = ',', nrows=100)\n",
    "\n",
    "y_train = []\n",
    "for index, row in train_label.iterrows():\n",
    "    if train_label[\"Unnamed: 2\"][index] == \"Normal\":\n",
    "        y_train.append(0)\n",
    "    if train_label[\"Unnamed: 2\"][index] == \"Fault\":\n",
    "        y_train.append(0)\n",
    "    if train_label[\"BP1\"][index] == \"Yes\":\n",
    "        y_train.append(1)\n",
    "    if train_label[\"BP2\"][index] == \"Yes\":\n",
    "        y_train.append(2)\n",
    "    if train_label[\"BP3\"][index] == \"Yes\":\n",
    "        y_train.append(3)\n",
    "    if train_label[\"BP4\"][index] == \"Yes\":\n",
    "        y_train.append(4)\n",
    "    if train_label[\"BP5\"][index] == \"Yes\":\n",
    "        y_train.append(5)\n",
    "    if train_label[\"BP6\"][index] == \"Yes\":\n",
    "        y_train.append(6)\n",
    "    if train_label[\"BP7\"][index] == \"Yes\":\n",
    "        y_train.append(7)\n",
    "    if train_label[\"BV1\"][index] == \"Yes\":\n",
    "        y_train.append(8)\n",
    "\n",
    "\n",
    "y_test = []\n",
    "for index, row in answers.iterrows():\n",
    "    if answers[\"Test condition\"][index] == \"Normal\":\n",
    "        y_test.append(0)\n",
    "    if \"valve fault\" in answers[\"Test condition\"][index]:\n",
    "        y_test.append(0)\n",
    "    if answers[\"Test condition\"][index] == \"BP1 bubble anomaly\":\n",
    "        y_test.append(1)\n",
    "    if answers[\"Test condition\"][index] == \"BP2 bubble anomaly\":\n",
    "        y_test.append(2)\n",
    "    if answers[\"Test condition\"][index] == \"BP3 bubble anomaly\":\n",
    "        y_test.append(3)\n",
    "    if answers[\"Test condition\"][index] == \"BP4 bubble anomaly\":\n",
    "        y_test.append(4)\n",
    "    if answers[\"Test condition\"][index] == \"BP5 bubble anomaly\":\n",
    "        y_test.append(5)\n",
    "    if answers[\"Test condition\"][index] == \"BP6 bubble anomaly\":\n",
    "        y_test.append(6)\n",
    "    if answers[\"Test condition\"][index] == \"BP7 bubble anomaly\":\n",
    "        y_test.append(7)\n",
    "    if answers[\"Test condition\"][index] == \"Unknown anomaly\":\n",
    "        y_test.append(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54537277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "def preprocess_data(data_dict, labels):\n",
    "    X = []\n",
    "    for key, value in data_dict.items():\n",
    "        X.append(value.values)\n",
    "    X = np.array(X)\n",
    "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)  # Add a channel dimension for Conv1D\n",
    "    y = np.array(labels)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = preprocess_data(Training_dict, y_train)\n",
    "X_test, y_test = preprocess_data(Testing_dict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "011bea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter training data\n",
    "X_trainV = X_train[y_train != 0]\n",
    "y_trainV = y_train[y_train != 0]\n",
    "\n",
    "# Filter testing data\n",
    "X_testV = X_test[y_test != 0]\n",
    "y_testV = y_test[y_test != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "887c7727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 100, 8, 1)\n",
      "(24,)\n",
      "(16, 100, 8, 1)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "print(X_trainV.shape)\n",
    "print(y_trainV.shape)\n",
    "print(X_testV.shape)\n",
    "print(y_testV.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "970be974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 13:04:12.923800: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 0.7464 - accuracy: 0.1579 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6205 - accuracy: 0.8421 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7822 - accuracy: 0.8421 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7683 - accuracy: 0.8421 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6787 - accuracy: 0.8421 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5549 - accuracy: 0.8421 - val_loss: 0.0984 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4513 - accuracy: 0.8421 - val_loss: 0.2515 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4439 - accuracy: 0.8421 - val_loss: 0.4454 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5330 - accuracy: 0.8421 - val_loss: 0.4857 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5551 - accuracy: 0.8421 - val_loss: 0.3700 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4871 - accuracy: 0.8421 - val_loss: 0.2281 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4269 - accuracy: 0.8421 - val_loss: 0.1331 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4184 - accuracy: 0.8421 - val_loss: 0.0847 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4400 - accuracy: 0.8421 - val_loss: 0.0651 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4593 - accuracy: 0.8421 - val_loss: 0.0602 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4636 - accuracy: 0.8421 - val_loss: 0.0648 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4530 - accuracy: 0.8421 - val_loss: 0.0785 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4322 - accuracy: 0.8421 - val_loss: 0.1026 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4100 - accuracy: 0.8421 - val_loss: 0.1379 - val_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3943 - accuracy: 0.8421 - val_loss: 0.1813 - val_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3901 - accuracy: 0.8421 - val_loss: 0.2220 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3943 - accuracy: 0.8421 - val_loss: 0.2453 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3968 - accuracy: 0.8421 - val_loss: 0.2388 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.3902 - accuracy: 0.8421 - val_loss: 0.2027 - val_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3761 - accuracy: 0.8421 - val_loss: 0.1500 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3672 - accuracy: 0.8421 - val_loss: 0.1134 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3706 - accuracy: 0.8421 - val_loss: 0.1090 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3676 - accuracy: 0.8421 - val_loss: 0.1247 - val_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3577 - accuracy: 0.8421 - val_loss: 0.1494 - val_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3494 - accuracy: 0.8421 - val_loss: 0.1767 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3452 - accuracy: 0.8421 - val_loss: 0.1951 - val_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3435 - accuracy: 0.8421 - val_loss: 0.1940 - val_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3378 - accuracy: 0.8421 - val_loss: 0.1787 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3296 - accuracy: 0.8421 - val_loss: 0.1575 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3224 - accuracy: 0.8421 - val_loss: 0.1393 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3173 - accuracy: 0.8421 - val_loss: 0.1302 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3132 - accuracy: 0.8421 - val_loss: 0.1311 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3076 - accuracy: 0.8421 - val_loss: 0.1398 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3009 - accuracy: 0.8421 - val_loss: 0.1495 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2953 - accuracy: 0.8421 - val_loss: 0.1583 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2899 - accuracy: 0.8421 - val_loss: 0.1597 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2845 - accuracy: 0.8421 - val_loss: 0.1525 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2785 - accuracy: 0.8421 - val_loss: 0.1407 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2731 - accuracy: 0.8421 - val_loss: 0.1354 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2677 - accuracy: 0.8421 - val_loss: 0.1388 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2617 - accuracy: 0.8421 - val_loss: 0.1470 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2560 - accuracy: 0.8421 - val_loss: 0.1523 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2508 - accuracy: 0.8421 - val_loss: 0.1497 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2448 - accuracy: 0.8421 - val_loss: 0.1389 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2386 - accuracy: 0.8421 - val_loss: 0.1296 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2332 - accuracy: 0.8421 - val_loss: 0.1280 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2278 - accuracy: 0.8421 - val_loss: 0.1351 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2218 - accuracy: 0.8421 - val_loss: 0.1436 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2164 - accuracy: 0.8421 - val_loss: 0.1429 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2108 - accuracy: 0.8421 - val_loss: 0.1344 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2047 - accuracy: 0.8421 - val_loss: 0.1254 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1995 - accuracy: 0.8421 - val_loss: 0.1214 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1940 - accuracy: 0.8421 - val_loss: 0.1253 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1879 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1828 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1773 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1720 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1674 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1624 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1579 - accuracy: 1.0000 - val_loss: 0.1113 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1533 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1491 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1446 - accuracy: 1.0000 - val_loss: 0.1140 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1406 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1366 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1326 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1291 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1250 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1214 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1178 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1145 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1113 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1080 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1048 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1015 - accuracy: 1.0000 - val_loss: 0.0821 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0983 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0954 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0926 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0897 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0871 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0842 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0816 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0791 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0766 - accuracy: 1.0000 - val_loss: 0.0618 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0742 - accuracy: 1.0000 - val_loss: 0.0610 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0717 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0695 - accuracy: 1.0000 - val_loss: 0.0591 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Test accuracy: 1.0\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "Confusion Matrix:\n",
      "[[14  0]\n",
      " [ 0  2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewweiner/opt/anaconda3/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# BUBBLE 1\n",
    "\n",
    "y_train1 = np.where(y_trainV != 1, 0, y_trainV)\n",
    "y_test1 = np.where(y_testV != 1, 0, y_testV)\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define and compile the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_trainV.shape[1], X_trainV.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))  # Assuming you have 4 classes\n",
    "custom_optimizer = Adam(lr=0.01)\n",
    "model.compile(optimizer=custom_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_trainV, y_train1, epochs=200, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_testV, y_test1)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_testV)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate and print confusion matrix\n",
    "conf_mat = confusion_matrix(y_test1, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "# Print classification report\n",
    "class_report = classification_report(y_test1, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "model.save('CNN_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25b6c28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 1.7272 - accuracy: 0.1579 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.0307 - accuracy: 0.8421 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.0102 - accuracy: 0.8421 - val_loss: 6.9141e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.1778 - accuracy: 0.8421 - val_loss: 2.7889 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.3997 - accuracy: 0.1579 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7447 - accuracy: 0.8421 - val_loss: 3.3192e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2062 - accuracy: 0.8421 - val_loss: 3.6815e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1903 - accuracy: 0.8421 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9114 - accuracy: 0.8421 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5637 - accuracy: 0.8421 - val_loss: 0.2015 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4056 - accuracy: 0.8421 - val_loss: 0.4758 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5368 - accuracy: 0.8421 - val_loss: 0.4437 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5165 - accuracy: 0.8421 - val_loss: 0.2659 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4238 - accuracy: 0.8421 - val_loss: 0.1381 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4004 - accuracy: 0.8421 - val_loss: 0.0874 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4227 - accuracy: 0.8421 - val_loss: 0.0776 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4297 - accuracy: 0.8421 - val_loss: 0.0915 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4157 - accuracy: 0.8421 - val_loss: 0.1147 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4014 - accuracy: 0.8421 - val_loss: 0.1526 - val_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3921 - accuracy: 0.8421 - val_loss: 0.1994 - val_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3941 - accuracy: 0.8421 - val_loss: 0.2329 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4006 - accuracy: 0.8421 - val_loss: 0.2355 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3981 - accuracy: 0.8421 - val_loss: 0.2055 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3845 - accuracy: 0.8421 - val_loss: 0.1573 - val_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3698 - accuracy: 0.8421 - val_loss: 0.1144 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3650 - accuracy: 0.8421 - val_loss: 0.0935 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3633 - accuracy: 0.8421 - val_loss: 0.0951 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3520 - accuracy: 0.8421 - val_loss: 0.1126 - val_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3360 - accuracy: 0.8421 - val_loss: 0.1388 - val_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3267 - accuracy: 0.8421 - val_loss: 0.1529 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3213 - accuracy: 0.8421 - val_loss: 0.1424 - val_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3095 - accuracy: 0.8421 - val_loss: 0.1138 - val_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2930 - accuracy: 0.8421 - val_loss: 0.0837 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2787 - accuracy: 0.8421 - val_loss: 0.0652 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2680 - accuracy: 0.8421 - val_loss: 0.0608 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2530 - accuracy: 0.8421 - val_loss: 0.0669 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2376 - accuracy: 0.8421 - val_loss: 0.0646 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2223 - accuracy: 0.8421 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2060 - accuracy: 0.8421 - val_loss: 0.0451 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1913 - accuracy: 0.8421 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1763 - accuracy: 0.8421 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1617 - accuracy: 0.8421 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1487 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1359 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1242 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1147 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1045 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0731 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0665 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 9.7622e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 8.8472e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 8.3092e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 7.7803e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 7.0177e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 5.9313e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.7115e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.5359e-04 - accuracy: 1.0000 - val_loss: 3.7653e-04 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.2666e-04 - accuracy: 1.0000 - val_loss: 3.0119e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.1282e-04 - accuracy: 1.0000 - val_loss: 2.4738e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.1520e-04 - accuracy: 1.0000 - val_loss: 2.1313e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.5447e-04 - accuracy: 1.0000 - val_loss: 1.9594e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.0740e-04 - accuracy: 1.0000 - val_loss: 1.8977e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.6603e-04 - accuracy: 1.0000 - val_loss: 1.9024e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3412e-04 - accuracy: 1.0000 - val_loss: 1.8879e-04 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.1359e-04 - accuracy: 1.0000 - val_loss: 1.7983e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.9409e-04 - accuracy: 1.0000 - val_loss: 1.6449e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.7161e-04 - accuracy: 1.0000 - val_loss: 1.4548e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.4973e-04 - accuracy: 1.0000 - val_loss: 1.2797e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3141e-04 - accuracy: 1.0000 - val_loss: 1.1217e-04 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.1839e-04 - accuracy: 1.0000 - val_loss: 1.0080e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0663e-04 - accuracy: 1.0000 - val_loss: 9.3725e-05 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.9668e-04 - accuracy: 1.0000 - val_loss: 9.0556e-05 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.8747e-04 - accuracy: 1.0000 - val_loss: 8.8625e-05 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7825e-04 - accuracy: 1.0000 - val_loss: 8.7434e-05 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6920e-04 - accuracy: 1.0000 - val_loss: 8.8220e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6154e-04 - accuracy: 1.0000 - val_loss: 9.0008e-05 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.5494e-04 - accuracy: 1.0000 - val_loss: 9.1914e-05 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4943e-04 - accuracy: 1.0000 - val_loss: 9.2987e-05 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4475e-04 - accuracy: 1.0000 - val_loss: 9.2677e-05 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4043e-04 - accuracy: 1.0000 - val_loss: 9.0723e-05 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3637e-04 - accuracy: 1.0000 - val_loss: 8.6981e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3231e-04 - accuracy: 1.0000 - val_loss: 8.2072e-05 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2824e-04 - accuracy: 1.0000 - val_loss: 7.6638e-05 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2446e-04 - accuracy: 1.0000 - val_loss: 7.1537e-05 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2129e-04 - accuracy: 1.0000 - val_loss: 6.7009e-05 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1845e-04 - accuracy: 1.0000 - val_loss: 6.3338e-05 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1590e-04 - accuracy: 1.0000 - val_loss: 6.0788e-05 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1352e-04 - accuracy: 1.0000 - val_loss: 5.9215e-05 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1113e-04 - accuracy: 1.0000 - val_loss: 5.8571e-05 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0876e-04 - accuracy: 1.0000 - val_loss: 5.8619e-05 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0645e-04 - accuracy: 1.0000 - val_loss: 5.9120e-05 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0427e-04 - accuracy: 1.0000 - val_loss: 5.9811e-05 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0239e-04 - accuracy: 1.0000 - val_loss: 5.9787e-05 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0048e-04 - accuracy: 1.0000 - val_loss: 5.9358e-05 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.8730e-05 - accuracy: 1.0000 - val_loss: 5.8762e-05 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.7118e-05 - accuracy: 1.0000 - val_loss: 5.7928e-05 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.5550e-05 - accuracy: 1.0000 - val_loss: 5.6951e-05 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 9.4076e-05 - accuracy: 1.0000 - val_loss: 5.5759e-05 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.2658e-05 - accuracy: 1.0000 - val_loss: 5.4543e-05 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 9.1303e-05 - accuracy: 1.0000 - val_loss: 5.3328e-05 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.0024e-05 - accuracy: 1.0000 - val_loss: 5.2088e-05 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 8.8769e-05 - accuracy: 1.0000 - val_loss: 5.0968e-05 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 8.7558e-05 - accuracy: 1.0000 - val_loss: 5.0038e-05 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.6429e-05 - accuracy: 1.0000 - val_loss: 4.9204e-05 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.5313e-05 - accuracy: 1.0000 - val_loss: 4.8536e-05 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 8.4209e-05 - accuracy: 1.0000 - val_loss: 4.7964e-05 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.3136e-05 - accuracy: 1.0000 - val_loss: 4.7535e-05 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.2101e-05 - accuracy: 1.0000 - val_loss: 4.7154e-05 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.1110e-05 - accuracy: 1.0000 - val_loss: 4.6749e-05 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.0106e-05 - accuracy: 1.0000 - val_loss: 4.6296e-05 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.9153e-05 - accuracy: 1.0000 - val_loss: 4.5819e-05 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.8243e-05 - accuracy: 1.0000 - val_loss: 4.5342e-05 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.7296e-05 - accuracy: 1.0000 - val_loss: 4.4842e-05 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6412e-05 - accuracy: 1.0000 - val_loss: 4.4317e-05 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.5534e-05 - accuracy: 1.0000 - val_loss: 4.3769e-05 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.4699e-05 - accuracy: 1.0000 - val_loss: 4.3245e-05 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.3859e-05 - accuracy: 1.0000 - val_loss: 4.2744e-05 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.3031e-05 - accuracy: 1.0000 - val_loss: 4.2220e-05 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.2228e-05 - accuracy: 1.0000 - val_loss: 4.1719e-05 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.1437e-05 - accuracy: 1.0000 - val_loss: 4.1242e-05 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.0697e-05 - accuracy: 1.0000 - val_loss: 4.0742e-05 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.9907e-05 - accuracy: 1.0000 - val_loss: 4.0265e-05 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.9185e-05 - accuracy: 1.0000 - val_loss: 3.9693e-05 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.8451e-05 - accuracy: 1.0000 - val_loss: 3.9073e-05 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.7692e-05 - accuracy: 1.0000 - val_loss: 3.8573e-05 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.6996e-05 - accuracy: 1.0000 - val_loss: 3.8144e-05 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.6300e-05 - accuracy: 1.0000 - val_loss: 3.7762e-05 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.5610e-05 - accuracy: 1.0000 - val_loss: 3.7428e-05 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.4945e-05 - accuracy: 1.0000 - val_loss: 3.7119e-05 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.4311e-05 - accuracy: 1.0000 - val_loss: 3.6499e-05 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.3608e-05 - accuracy: 1.0000 - val_loss: 3.5927e-05 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.2987e-05 - accuracy: 1.0000 - val_loss: 3.4973e-05 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.2391e-05 - accuracy: 1.0000 - val_loss: 3.4210e-05 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.1783e-05 - accuracy: 1.0000 - val_loss: 3.3686e-05 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.1187e-05 - accuracy: 1.0000 - val_loss: 3.3376e-05 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.0629e-05 - accuracy: 1.0000 - val_loss: 3.3209e-05 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.9995e-05 - accuracy: 1.0000 - val_loss: 3.3209e-05 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.9393e-05 - accuracy: 1.0000 - val_loss: 3.3281e-05 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.8791e-05 - accuracy: 1.0000 - val_loss: 3.3400e-05 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.8232e-05 - accuracy: 1.0000 - val_loss: 3.3471e-05 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.7668e-05 - accuracy: 1.0000 - val_loss: 3.3424e-05 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.7153e-05 - accuracy: 1.0000 - val_loss: 3.3138e-05 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.6570e-05 - accuracy: 1.0000 - val_loss: 3.2804e-05 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.6037e-05 - accuracy: 1.0000 - val_loss: 3.2422e-05 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.5516e-05 - accuracy: 1.0000 - val_loss: 3.1993e-05 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.4989e-05 - accuracy: 1.0000 - val_loss: 3.1588e-05 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.4456e-05 - accuracy: 1.0000 - val_loss: 3.1159e-05 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.3948e-05 - accuracy: 1.0000 - val_loss: 3.0730e-05 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.3440e-05 - accuracy: 1.0000 - val_loss: 3.0325e-05 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.2944e-05 - accuracy: 1.0000 - val_loss: 2.9991e-05 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.2467e-05 - accuracy: 1.0000 - val_loss: 2.9657e-05 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.1991e-05 - accuracy: 1.0000 - val_loss: 2.9347e-05 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.1489e-05 - accuracy: 1.0000 - val_loss: 2.9085e-05 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.1031e-05 - accuracy: 1.0000 - val_loss: 2.8871e-05 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.0579e-05 - accuracy: 1.0000 - val_loss: 2.8656e-05 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.0165e-05 - accuracy: 1.0000 - val_loss: 2.8203e-05 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.9682e-05 - accuracy: 1.0000 - val_loss: 2.7774e-05 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.9249e-05 - accuracy: 1.0000 - val_loss: 2.7440e-05 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.8791e-05 - accuracy: 1.0000 - val_loss: 2.7154e-05 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.8415e-05 - accuracy: 1.0000 - val_loss: 2.6582e-05 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.7944e-05 - accuracy: 1.0000 - val_loss: 2.6081e-05 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.7568e-05 - accuracy: 1.0000 - val_loss: 2.5605e-05 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.7147e-05 - accuracy: 1.0000 - val_loss: 2.5295e-05 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.6758e-05 - accuracy: 1.0000 - val_loss: 2.5128e-05 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.6351e-05 - accuracy: 1.0000 - val_loss: 2.5080e-05 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.5968e-05 - accuracy: 1.0000 - val_loss: 2.5032e-05 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.5529e-05 - accuracy: 1.0000 - val_loss: 2.5009e-05 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.5140e-05 - accuracy: 1.0000 - val_loss: 2.5009e-05 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.4745e-05 - accuracy: 1.0000 - val_loss: 2.4985e-05 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4337e-05 - accuracy: 1.0000 - val_loss: 2.5009e-05 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.3954e-05 - accuracy: 1.0000 - val_loss: 2.5009e-05 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.3597e-05 - accuracy: 1.0000 - val_loss: 2.4818e-05 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.3252e-05 - accuracy: 1.0000 - val_loss: 2.4413e-05 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.2850e-05 - accuracy: 1.0000 - val_loss: 2.3721e-05 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.2524e-05 - accuracy: 1.0000 - val_loss: 2.3149e-05 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.2204e-05 - accuracy: 1.0000 - val_loss: 2.2696e-05 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.1890e-05 - accuracy: 1.0000 - val_loss: 2.2386e-05 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.1539e-05 - accuracy: 1.0000 - val_loss: 2.2196e-05 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1213e-05 - accuracy: 1.0000 - val_loss: 2.2124e-05 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.0855e-05 - accuracy: 1.0000 - val_loss: 2.2148e-05 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.0529e-05 - accuracy: 1.0000 - val_loss: 2.2196e-05 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0159e-05 - accuracy: 1.0000 - val_loss: 2.2315e-05 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Test accuracy: 1.0\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Confusion Matrix:\n",
      "[[14  0]\n",
      " [ 0  2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BUBBLE 2\n",
    "\n",
    "y_train2 = np.where(y_trainV != 2, 0, 1)\n",
    "y_test2 = np.where(y_testV != 2, 0, 1)\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define and compile the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_trainV.shape[1], X_trainV.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))  # Assuming you have 4 classes\n",
    "custom_optimizer = Adam(lr=0.01)\n",
    "model.compile(optimizer=custom_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_trainV, y_train2, epochs=200, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_testV, y_test2)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_testV)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate and print confusion matrix\n",
    "conf_mat = confusion_matrix(y_test2, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "# Print classification report\n",
    "class_report = classification_report(y_test2, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54801171",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewweiner/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 473ms/step - loss: 0.6147 - accuracy: 0.8421 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.6332 - accuracy: 0.8421 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.8633 - accuracy: 0.8421 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.7062 - accuracy: 0.8421 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8097 - accuracy: 0.8421 - val_loss: 0.4783 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5333 - accuracy: 0.8421 - val_loss: 0.7261 - val_accuracy: 0.2000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7077 - accuracy: 0.2632 - val_loss: 0.4065 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5001 - accuracy: 0.8421 - val_loss: 0.1520 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4134 - accuracy: 0.8421 - val_loss: 0.0506 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4837 - accuracy: 0.8421 - val_loss: 0.0742 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4368 - accuracy: 0.8421 - val_loss: 0.1683 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3942 - accuracy: 0.8421 - val_loss: 0.2231 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3974 - accuracy: 0.8421 - val_loss: 0.2142 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3822 - accuracy: 0.8421 - val_loss: 0.1556 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3556 - accuracy: 0.8421 - val_loss: 0.0809 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3562 - accuracy: 0.8421 - val_loss: 0.1124 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3200 - accuracy: 0.8421 - val_loss: 0.1446 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3038 - accuracy: 0.8421 - val_loss: 0.1082 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2821 - accuracy: 0.8421 - val_loss: 0.0836 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2622 - accuracy: 0.8421 - val_loss: 0.0986 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2319 - accuracy: 0.8421 - val_loss: 0.0944 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2046 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1824 - accuracy: 0.8421 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1480 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1260 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0984 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0739 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0550 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 8.1306e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 7.4058e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 7.8969e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.3812e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.7144e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.9590e-04 - accuracy: 1.0000 - val_loss: 1.9202e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.0148e-04 - accuracy: 1.0000 - val_loss: 1.1902e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7837e-04 - accuracy: 1.0000 - val_loss: 9.1584e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.8450e-04 - accuracy: 1.0000 - val_loss: 8.0811e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.1235e-04 - accuracy: 1.0000 - val_loss: 7.5758e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6498e-04 - accuracy: 1.0000 - val_loss: 7.0705e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3413e-04 - accuracy: 1.0000 - val_loss: 6.3102e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1126e-04 - accuracy: 1.0000 - val_loss: 5.3233e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.2346e-05 - accuracy: 1.0000 - val_loss: 4.2792e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.6444e-05 - accuracy: 1.0000 - val_loss: 3.3329e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.3710e-05 - accuracy: 1.0000 - val_loss: 2.5724e-05 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.4650e-04 - accuracy: 1.0000\n",
      "Test accuracy: 1.0\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Confusion Matrix:\n",
      "[[15  0]\n",
      " [ 0  1]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BUBBLE 3\n",
    "\n",
    "y_train3 = np.where(y_trainV != 3, 0, 1)\n",
    "y_test3 = np.where(y_testV != 3, 0, 1)\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define and compile the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_trainV.shape[1], X_trainV.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))  # Assuming you have 4 classes\n",
    "custom_optimizer = Adam(lr=0.01)\n",
    "model.compile(optimizer=custom_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_trainV, y_train3, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_testV, y_test3)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_testV)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate and print confusion matrix\n",
    "conf_mat = confusion_matrix(y_test3, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "# Print classification report\n",
    "class_report = classification_report(y_test3, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b64ecdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewweiner/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 458ms/step - loss: 0.5040 - accuracy: 0.8947 - val_loss: 5.9991 - val_accuracy: 0.8000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.1574 - accuracy: 0.8947 - val_loss: 4.6259 - val_accuracy: 0.8000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.4347 - accuracy: 0.8947 - val_loss: 2.5127 - val_accuracy: 0.8000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3225 - accuracy: 0.8947 - val_loss: 0.5493 - val_accuracy: 0.8000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3300 - accuracy: 0.8947 - val_loss: 3.2236 - val_accuracy: 0.2000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.5883 - accuracy: 0.1053 - val_loss: 1.4589 - val_accuracy: 0.2000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.6071 - accuracy: 0.1053 - val_loss: 0.6274 - val_accuracy: 0.8000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6092 - accuracy: 0.8947 - val_loss: 0.5064 - val_accuracy: 0.8000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4086 - accuracy: 0.8947 - val_loss: 0.4923 - val_accuracy: 0.8000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3527 - accuracy: 0.8947 - val_loss: 0.5323 - val_accuracy: 0.8000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3300 - accuracy: 0.8947 - val_loss: 0.5990 - val_accuracy: 0.8000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3442 - accuracy: 0.8947 - val_loss: 0.6119 - val_accuracy: 0.8000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3480 - accuracy: 0.8947 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3317 - accuracy: 0.8947 - val_loss: 0.4973 - val_accuracy: 0.8000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3272 - accuracy: 0.8947 - val_loss: 0.4761 - val_accuracy: 0.8000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3464 - accuracy: 0.8947 - val_loss: 0.4821 - val_accuracy: 0.8000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3286 - accuracy: 0.8947 - val_loss: 0.5468 - val_accuracy: 0.8000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3256 - accuracy: 0.8947 - val_loss: 0.5582 - val_accuracy: 0.8000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3269 - accuracy: 0.8947 - val_loss: 0.4828 - val_accuracy: 0.8000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3133 - accuracy: 0.8947 - val_loss: 0.4538 - val_accuracy: 0.8000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3168 - accuracy: 0.8947 - val_loss: 0.5240 - val_accuracy: 0.8000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3111 - accuracy: 0.8947 - val_loss: 0.5197 - val_accuracy: 0.8000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3072 - accuracy: 0.8947 - val_loss: 0.4353 - val_accuracy: 0.8000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2940 - accuracy: 0.8947 - val_loss: 0.4080 - val_accuracy: 0.8000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2927 - accuracy: 0.8947 - val_loss: 0.4558 - val_accuracy: 0.8000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2805 - accuracy: 0.8947 - val_loss: 0.4596 - val_accuracy: 0.8000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2767 - accuracy: 0.8947 - val_loss: 0.3900 - val_accuracy: 0.8000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2593 - accuracy: 0.8947 - val_loss: 0.3418 - val_accuracy: 0.8000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2563 - accuracy: 0.8947 - val_loss: 0.3555 - val_accuracy: 0.8000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2351 - accuracy: 0.8947 - val_loss: 0.3687 - val_accuracy: 0.8000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2273 - accuracy: 0.8947 - val_loss: 0.3077 - val_accuracy: 0.8000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2064 - accuracy: 0.8947 - val_loss: 0.2595 - val_accuracy: 0.8000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1999 - accuracy: 0.8947 - val_loss: 0.2588 - val_accuracy: 0.8000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1747 - accuracy: 0.8947 - val_loss: 0.2607 - val_accuracy: 0.8000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1632 - accuracy: 0.8947 - val_loss: 0.2016 - val_accuracy: 0.8000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1433 - accuracy: 0.8947 - val_loss: 0.1808 - val_accuracy: 0.8000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1248 - accuracy: 0.8947 - val_loss: 0.1834 - val_accuracy: 0.8000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1126 - accuracy: 0.8947 - val_loss: 0.1429 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.8000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0899 - accuracy: 0.8947 - val_loss: 0.1034 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 9.5819e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.4598e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 8.3599e-04 - accuracy: 1.0000 - val_loss: 8.1799e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.7531e-04 - accuracy: 1.0000 - val_loss: 5.1964e-04 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.7502e-04 - accuracy: 1.0000 - val_loss: 3.5498e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.4091e-04 - accuracy: 1.0000 - val_loss: 2.8973e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.9916e-04 - accuracy: 1.0000 - val_loss: 2.8756e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.2977e-04 - accuracy: 1.0000 - val_loss: 3.2586e-04 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.6841e-04 - accuracy: 1.0000 - val_loss: 3.8207e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.3835e-04 - accuracy: 1.0000 - val_loss: 4.2083e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.2513e-04 - accuracy: 1.0000 - val_loss: 4.1038e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.0594e-04 - accuracy: 1.0000 - val_loss: 3.5374e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.7624e-04 - accuracy: 1.0000 - val_loss: 2.7995e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.4690e-04 - accuracy: 1.0000 - val_loss: 2.1561e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.2781e-04 - accuracy: 1.0000 - val_loss: 1.7116e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1848e-04 - accuracy: 1.0000 - val_loss: 1.4612e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.1176e-04 - accuracy: 1.0000 - val_loss: 1.3645e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.0153e-04 - accuracy: 1.0000 - val_loss: 1.3876e-04 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.8806e-04 - accuracy: 1.0000 - val_loss: 1.4965e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7550e-04 - accuracy: 1.0000 - val_loss: 1.6518e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.6701e-04 - accuracy: 1.0000 - val_loss: 1.8017e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6238e-04 - accuracy: 1.0000 - val_loss: 1.8893e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5919e-04 - accuracy: 1.0000 - val_loss: 1.8772e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.5497e-04 - accuracy: 1.0000 - val_loss: 1.7666e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4910e-04 - accuracy: 1.0000 - val_loss: 1.5934e-04 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4271e-04 - accuracy: 1.0000 - val_loss: 1.4114e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3769e-04 - accuracy: 1.0000 - val_loss: 1.2501e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3420e-04 - accuracy: 1.0000 - val_loss: 1.1284e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.3186e-04 - accuracy: 1.0000 - val_loss: 1.0514e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2965e-04 - accuracy: 1.0000 - val_loss: 1.0188e-04 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2690e-04 - accuracy: 1.0000 - val_loss: 1.0257e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2380e-04 - accuracy: 1.0000 - val_loss: 1.0605e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2063e-04 - accuracy: 1.0000 - val_loss: 1.1119e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1795e-04 - accuracy: 1.0000 - val_loss: 1.1667e-04 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1598e-04 - accuracy: 1.0000 - val_loss: 1.2101e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1452e-04 - accuracy: 1.0000 - val_loss: 1.2296e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1316e-04 - accuracy: 1.0000 - val_loss: 1.2199e-04 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1161e-04 - accuracy: 1.0000 - val_loss: 1.1825e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0981e-04 - accuracy: 1.0000 - val_loss: 1.1262e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0794e-04 - accuracy: 1.0000 - val_loss: 1.0626e-04 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0631e-04 - accuracy: 1.0000 - val_loss: 1.0018e-04 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0495e-04 - accuracy: 1.0000 - val_loss: 9.5226e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0387e-04 - accuracy: 1.0000 - val_loss: 9.1747e-05 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0285e-04 - accuracy: 1.0000 - val_loss: 8.9888e-05 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0179e-04 - accuracy: 1.0000 - val_loss: 8.9578e-05 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0061e-04 - accuracy: 1.0000 - val_loss: 9.0508e-05 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.9390e-05 - accuracy: 1.0000 - val_loss: 9.2319e-05 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.8254e-05 - accuracy: 1.0000 - val_loss: 9.4392e-05 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.7200e-05 - accuracy: 1.0000 - val_loss: 9.6275e-05 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.6309e-05 - accuracy: 1.0000 - val_loss: 9.7419e-05 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.5500e-05 - accuracy: 1.0000 - val_loss: 9.7538e-05 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 9.4660e-05 - accuracy: 1.0000 - val_loss: 9.6537e-05 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.3775e-05 - accuracy: 1.0000 - val_loss: 9.4607e-05 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.2872e-05 - accuracy: 1.0000 - val_loss: 9.2033e-05 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.1969e-05 - accuracy: 1.0000 - val_loss: 8.9221e-05 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.1091e-05 - accuracy: 1.0000 - val_loss: 8.6599e-05 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.0333e-05 - accuracy: 1.0000 - val_loss: 8.4383e-05 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.9561e-05 - accuracy: 1.0000 - val_loss: 8.2786e-05 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.8834e-05 - accuracy: 1.0000 - val_loss: 8.1809e-05 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.8056e-05 - accuracy: 1.0000 - val_loss: 8.1523e-05 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.7303e-05 - accuracy: 1.0000 - val_loss: 8.1690e-05 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.6526e-05 - accuracy: 1.0000 - val_loss: 8.2166e-05 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 8.5798e-05 - accuracy: 1.0000 - val_loss: 8.2715e-05 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.5051e-05 - accuracy: 1.0000 - val_loss: 8.3167e-05 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.4386e-05 - accuracy: 1.0000 - val_loss: 8.3263e-05 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.3684e-05 - accuracy: 1.0000 - val_loss: 8.2953e-05 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 8.3032e-05 - accuracy: 1.0000 - val_loss: 8.2190e-05 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.2329e-05 - accuracy: 1.0000 - val_loss: 8.1070e-05 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.1645e-05 - accuracy: 1.0000 - val_loss: 7.9688e-05 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.0937e-05 - accuracy: 1.0000 - val_loss: 7.8234e-05 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 8.0285e-05 - accuracy: 1.0000 - val_loss: 7.6828e-05 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.9620e-05 - accuracy: 1.0000 - val_loss: 7.5565e-05 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.8955e-05 - accuracy: 1.0000 - val_loss: 7.4564e-05 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.8315e-05 - accuracy: 1.0000 - val_loss: 7.3801e-05 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.7650e-05 - accuracy: 1.0000 - val_loss: 7.3325e-05 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.6948e-05 - accuracy: 1.0000 - val_loss: 7.3062e-05 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.6302e-05 - accuracy: 1.0000 - val_loss: 7.2919e-05 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.5643e-05 - accuracy: 1.0000 - val_loss: 7.2824e-05 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.4991e-05 - accuracy: 1.0000 - val_loss: 7.2657e-05 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.4320e-05 - accuracy: 1.0000 - val_loss: 7.2371e-05 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.3661e-05 - accuracy: 1.0000 - val_loss: 7.1918e-05 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.3009e-05 - accuracy: 1.0000 - val_loss: 7.1322e-05 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.2356e-05 - accuracy: 1.0000 - val_loss: 7.0584e-05 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.1723e-05 - accuracy: 1.0000 - val_loss: 6.9749e-05 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.1077e-05 - accuracy: 1.0000 - val_loss: 6.8868e-05 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.0424e-05 - accuracy: 1.0000 - val_loss: 6.7986e-05 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.9791e-05 - accuracy: 1.0000 - val_loss: 6.7128e-05 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.9151e-05 - accuracy: 1.0000 - val_loss: 6.6389e-05 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.8536e-05 - accuracy: 1.0000 - val_loss: 6.5722e-05 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 6.7941e-05 - accuracy: 1.0000 - val_loss: 6.5126e-05 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.7326e-05 - accuracy: 1.0000 - val_loss: 6.4625e-05 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6.6742e-05 - accuracy: 1.0000 - val_loss: 6.4172e-05 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.6109e-05 - accuracy: 1.0000 - val_loss: 6.3719e-05 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.5494e-05 - accuracy: 1.0000 - val_loss: 6.3290e-05 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.4892e-05 - accuracy: 1.0000 - val_loss: 6.2838e-05 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.4315e-05 - accuracy: 1.0000 - val_loss: 6.2337e-05 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.3694e-05 - accuracy: 1.0000 - val_loss: 6.1789e-05 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.3067e-05 - accuracy: 1.0000 - val_loss: 6.1193e-05 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.2433e-05 - accuracy: 1.0000 - val_loss: 6.0645e-05 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.1881e-05 - accuracy: 1.0000 - val_loss: 6.0049e-05 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.1360e-05 - accuracy: 1.0000 - val_loss: 5.9429e-05 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.0827e-05 - accuracy: 1.0000 - val_loss: 5.8762e-05 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.0307e-05 - accuracy: 1.0000 - val_loss: 5.8118e-05 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.9761e-05 - accuracy: 1.0000 - val_loss: 5.7499e-05 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.9228e-05 - accuracy: 1.0000 - val_loss: 5.6903e-05 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.8688e-05 - accuracy: 1.0000 - val_loss: 5.6402e-05 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.8143e-05 - accuracy: 1.0000 - val_loss: 5.5925e-05 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.7609e-05 - accuracy: 1.0000 - val_loss: 5.5473e-05 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.7051e-05 - accuracy: 1.0000 - val_loss: 5.5067e-05 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.6537e-05 - accuracy: 1.0000 - val_loss: 5.4662e-05 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.6004e-05 - accuracy: 1.0000 - val_loss: 5.4233e-05 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.5477e-05 - accuracy: 1.0000 - val_loss: 5.3804e-05 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.4950e-05 - accuracy: 1.0000 - val_loss: 5.3494e-05 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.4486e-05 - accuracy: 1.0000 - val_loss: 5.3113e-05 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.4040e-05 - accuracy: 1.0000 - val_loss: 5.2684e-05 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.3607e-05 - accuracy: 1.0000 - val_loss: 5.2159e-05 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.3162e-05 - accuracy: 1.0000 - val_loss: 5.1587e-05 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.2710e-05 - accuracy: 1.0000 - val_loss: 5.1015e-05 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.2277e-05 - accuracy: 1.0000 - val_loss: 5.0443e-05 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.1863e-05 - accuracy: 1.0000 - val_loss: 4.9895e-05 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.1424e-05 - accuracy: 1.0000 - val_loss: 4.9418e-05 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.1023e-05 - accuracy: 1.0000 - val_loss: 4.8965e-05 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.0596e-05 - accuracy: 1.0000 - val_loss: 4.8560e-05 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.0176e-05 - accuracy: 1.0000 - val_loss: 4.8226e-05 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.9793e-05 - accuracy: 1.0000 - val_loss: 4.7869e-05 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.9361e-05 - accuracy: 1.0000 - val_loss: 4.7583e-05 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.8965e-05 - accuracy: 1.0000 - val_loss: 4.7297e-05 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.8570e-05 - accuracy: 1.0000 - val_loss: 4.7011e-05 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.8194e-05 - accuracy: 1.0000 - val_loss: 4.6701e-05 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.7805e-05 - accuracy: 1.0000 - val_loss: 4.6367e-05 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.7403e-05 - accuracy: 1.0000 - val_loss: 4.6034e-05 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.7021e-05 - accuracy: 1.0000 - val_loss: 4.5652e-05 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.6651e-05 - accuracy: 1.0000 - val_loss: 4.5271e-05 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.6262e-05 - accuracy: 1.0000 - val_loss: 4.4889e-05 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.5892e-05 - accuracy: 1.0000 - val_loss: 4.4532e-05 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.5553e-05 - accuracy: 1.0000 - val_loss: 4.4150e-05 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.5164e-05 - accuracy: 1.0000 - val_loss: 4.3793e-05 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.4806e-05 - accuracy: 1.0000 - val_loss: 4.3435e-05 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.4449e-05 - accuracy: 1.0000 - val_loss: 4.3078e-05 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.4091e-05 - accuracy: 1.0000 - val_loss: 4.2720e-05 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3734e-05 - accuracy: 1.0000 - val_loss: 4.2386e-05 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.3389e-05 - accuracy: 1.0000 - val_loss: 4.2053e-05 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.3044e-05 - accuracy: 1.0000 - val_loss: 4.1767e-05 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Test accuracy: 1.0\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Confusion Matrix:\n",
      "[[15  0]\n",
      " [ 0  1]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BUBBLE 4\n",
    "\n",
    "y_train4 = np.where(y_trainV != 4, 0, 1)\n",
    "y_test4 = np.where(y_testV != 4, 0, 1)\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define and compile the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_trainV.shape[1], X_trainV.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))  # Assuming you have 4 classes\n",
    "custom_optimizer = Adam(lr=0.01)\n",
    "model.compile(optimizer=custom_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_trainV, y_train4, epochs=200, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_testV, y_test4)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_testV)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate and print confusion matrix\n",
    "conf_mat = confusion_matrix(y_test4, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "# Print classification report\n",
    "class_report = classification_report(y_test4, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67aee6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewweiner/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 463ms/step - loss: 0.3432 - accuracy: 0.8947 - val_loss: 8.7231 - val_accuracy: 0.8000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.5911 - accuracy: 0.8947 - val_loss: 2.5896 - val_accuracy: 0.8000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3629 - accuracy: 0.8947 - val_loss: 1.8385 - val_accuracy: 0.2000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.0429 - accuracy: 0.1053 - val_loss: 0.7427 - val_accuracy: 0.2000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7591 - accuracy: 0.1053 - val_loss: 0.5478 - val_accuracy: 0.8000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4839 - accuracy: 0.8947 - val_loss: 0.4990 - val_accuracy: 0.8000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3619 - accuracy: 0.8947 - val_loss: 0.5542 - val_accuracy: 0.8000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3370 - accuracy: 0.8947 - val_loss: 0.6060 - val_accuracy: 0.8000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3481 - accuracy: 0.8947 - val_loss: 0.5934 - val_accuracy: 0.8000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3429 - accuracy: 0.8947 - val_loss: 0.4833 - val_accuracy: 0.8000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3331 - accuracy: 0.8947 - val_loss: 0.5038 - val_accuracy: 0.8000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3055 - accuracy: 0.8947 - val_loss: 0.4492 - val_accuracy: 0.8000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2944 - accuracy: 0.8947 - val_loss: 0.4945 - val_accuracy: 0.8000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2912 - accuracy: 0.8947 - val_loss: 0.4074 - val_accuracy: 0.8000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3430 - accuracy: 0.8947 - val_loss: 0.7649 - val_accuracy: 0.8000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4071 - accuracy: 0.8947 - val_loss: 0.8132 - val_accuracy: 0.8000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.4309 - accuracy: 0.8947 - val_loss: 0.4895 - val_accuracy: 0.8000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2740 - accuracy: 0.8947 - val_loss: 0.4034 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3703 - accuracy: 1.0000 - val_loss: 0.3425 - val_accuracy: 0.8000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2446 - accuracy: 0.8947 - val_loss: 0.4441 - val_accuracy: 0.8000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2544 - accuracy: 0.8947 - val_loss: 0.4883 - val_accuracy: 0.8000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2722 - accuracy: 0.8947 - val_loss: 0.4302 - val_accuracy: 0.8000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2478 - accuracy: 0.8947 - val_loss: 0.3483 - val_accuracy: 0.8000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2182 - accuracy: 0.8947 - val_loss: 0.3206 - val_accuracy: 0.8000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2164 - accuracy: 0.8947 - val_loss: 0.3586 - val_accuracy: 0.8000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2088 - accuracy: 0.8947 - val_loss: 0.2571 - val_accuracy: 0.8000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1635 - accuracy: 0.8947 - val_loss: 0.2214 - val_accuracy: 0.8000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1411 - accuracy: 0.8947 - val_loss: 0.2789 - val_accuracy: 0.8000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1521 - accuracy: 0.8947 - val_loss: 0.2389 - val_accuracy: 0.8000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1796 - accuracy: 0.8947 - val_loss: 0.1807 - val_accuracy: 0.8000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0997 - accuracy: 0.8947 - val_loss: 0.2400 - val_accuracy: 0.8000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1282 - accuracy: 0.8947 - val_loss: 0.1085 - val_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0644 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0917 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.8977e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.7542e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 9.1960e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.6993e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.4755e-04 - accuracy: 1.0000 - val_loss: 9.3990e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.8151e-04 - accuracy: 1.0000 - val_loss: 8.6984e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.6516e-04 - accuracy: 1.0000 - val_loss: 8.4842e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.7255e-04 - accuracy: 1.0000 - val_loss: 8.3343e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.7641e-04 - accuracy: 1.0000 - val_loss: 8.0143e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.6086e-04 - accuracy: 1.0000 - val_loss: 7.4877e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.2417e-04 - accuracy: 1.0000 - val_loss: 6.8628e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.7542e-04 - accuracy: 1.0000 - val_loss: 6.2884e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.2676e-04 - accuracy: 1.0000 - val_loss: 5.8909e-04 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8828e-04 - accuracy: 1.0000 - val_loss: 5.7327e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6515e-04 - accuracy: 1.0000 - val_loss: 5.7541e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.5504e-04 - accuracy: 1.0000 - val_loss: 5.8491e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.5210e-04 - accuracy: 1.0000 - val_loss: 5.9092e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.5010e-04 - accuracy: 1.0000 - val_loss: 5.8530e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.4436e-04 - accuracy: 1.0000 - val_loss: 5.6517e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.3279e-04 - accuracy: 1.0000 - val_loss: 5.3308e-04 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.1646e-04 - accuracy: 1.0000 - val_loss: 4.9513e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.9833e-04 - accuracy: 1.0000 - val_loss: 4.5761e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.8143e-04 - accuracy: 1.0000 - val_loss: 4.2479e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.6773e-04 - accuracy: 1.0000 - val_loss: 3.9861e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.5788e-04 - accuracy: 1.0000 - val_loss: 3.7885e-04 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.5136e-04 - accuracy: 1.0000 - val_loss: 3.6478e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.4725e-04 - accuracy: 1.0000 - val_loss: 3.5402e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.4392e-04 - accuracy: 1.0000 - val_loss: 3.4477e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.4011e-04 - accuracy: 1.0000 - val_loss: 3.3605e-04 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.3520e-04 - accuracy: 1.0000 - val_loss: 3.2745e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.2905e-04 - accuracy: 1.0000 - val_loss: 3.1904e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.2197e-04 - accuracy: 1.0000 - val_loss: 3.1144e-04 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.1464e-04 - accuracy: 1.0000 - val_loss: 3.0503e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.0761e-04 - accuracy: 1.0000 - val_loss: 3.0009e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.0135e-04 - accuracy: 1.0000 - val_loss: 2.9670e-04 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.9612e-04 - accuracy: 1.0000 - val_loss: 2.9441e-04 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.9188e-04 - accuracy: 1.0000 - val_loss: 2.9255e-04 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8834e-04 - accuracy: 1.0000 - val_loss: 2.9052e-04 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.8526e-04 - accuracy: 1.0000 - val_loss: 2.8764e-04 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.8220e-04 - accuracy: 1.0000 - val_loss: 2.8356e-04 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7900e-04 - accuracy: 1.0000 - val_loss: 2.7813e-04 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7550e-04 - accuracy: 1.0000 - val_loss: 2.7155e-04 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7176e-04 - accuracy: 1.0000 - val_loss: 2.6412e-04 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6787e-04 - accuracy: 1.0000 - val_loss: 2.5629e-04 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6399e-04 - accuracy: 1.0000 - val_loss: 2.4842e-04 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.6028e-04 - accuracy: 1.0000 - val_loss: 2.4087e-04 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5682e-04 - accuracy: 1.0000 - val_loss: 2.3375e-04 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5359e-04 - accuracy: 1.0000 - val_loss: 2.2734e-04 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5071e-04 - accuracy: 1.0000 - val_loss: 2.2172e-04 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4807e-04 - accuracy: 1.0000 - val_loss: 2.1650e-04 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4546e-04 - accuracy: 1.0000 - val_loss: 2.1164e-04 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4284e-04 - accuracy: 1.0000 - val_loss: 2.0738e-04 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4031e-04 - accuracy: 1.0000 - val_loss: 2.0342e-04 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3776e-04 - accuracy: 1.0000 - val_loss: 1.9973e-04 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3520e-04 - accuracy: 1.0000 - val_loss: 1.9632e-04 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.3269e-04 - accuracy: 1.0000 - val_loss: 1.9317e-04 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3022e-04 - accuracy: 1.0000 - val_loss: 1.9019e-04 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2777e-04 - accuracy: 1.0000 - val_loss: 1.8738e-04 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2537e-04 - accuracy: 1.0000 - val_loss: 1.8476e-04 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2312e-04 - accuracy: 1.0000 - val_loss: 1.8214e-04 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2089e-04 - accuracy: 1.0000 - val_loss: 1.7942e-04 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1871e-04 - accuracy: 1.0000 - val_loss: 1.7670e-04 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1660e-04 - accuracy: 1.0000 - val_loss: 1.7389e-04 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1454e-04 - accuracy: 1.0000 - val_loss: 1.7093e-04 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1246e-04 - accuracy: 1.0000 - val_loss: 1.6791e-04 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1045e-04 - accuracy: 1.0000 - val_loss: 1.6476e-04 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0846e-04 - accuracy: 1.0000 - val_loss: 1.6147e-04 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.0644e-04 - accuracy: 1.0000 - val_loss: 1.5816e-04 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0445e-04 - accuracy: 1.0000 - val_loss: 1.5485e-04 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0254e-04 - accuracy: 1.0000 - val_loss: 1.5156e-04 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0066e-04 - accuracy: 1.0000 - val_loss: 1.4832e-04 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.8804e-05 - accuracy: 1.0000 - val_loss: 1.4515e-04 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.6985e-05 - accuracy: 1.0000 - val_loss: 1.4210e-04 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.5229e-05 - accuracy: 1.0000 - val_loss: 1.3912e-04 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.3510e-05 - accuracy: 1.0000 - val_loss: 1.3616e-04 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.1804e-05 - accuracy: 1.0000 - val_loss: 1.3340e-04 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.0161e-05 - accuracy: 1.0000 - val_loss: 1.3066e-04 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.8511e-05 - accuracy: 1.0000 - val_loss: 1.2806e-04 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 8.6956e-05 - accuracy: 1.0000 - val_loss: 1.2553e-04 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 8.5381e-05 - accuracy: 1.0000 - val_loss: 1.2310e-04 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 8.3895e-05 - accuracy: 1.0000 - val_loss: 1.2081e-04 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 8.2446e-05 - accuracy: 1.0000 - val_loss: 1.1857e-04 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.1003e-05 - accuracy: 1.0000 - val_loss: 1.1650e-04 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.9629e-05 - accuracy: 1.0000 - val_loss: 1.1443e-04 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 7.8255e-05 - accuracy: 1.0000 - val_loss: 1.1247e-04 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.6907e-05 - accuracy: 1.0000 - val_loss: 1.1056e-04 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.5602e-05 - accuracy: 1.0000 - val_loss: 1.0882e-04 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.4404e-05 - accuracy: 1.0000 - val_loss: 1.0716e-04 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.3243e-05 - accuracy: 1.0000 - val_loss: 1.0549e-04 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.2102e-05 - accuracy: 1.0000 - val_loss: 1.0387e-04 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.0985e-05 - accuracy: 1.0000 - val_loss: 1.0227e-04 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.9919e-05 - accuracy: 1.0000 - val_loss: 1.0070e-04 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.8865e-05 - accuracy: 1.0000 - val_loss: 9.9122e-05 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.7811e-05 - accuracy: 1.0000 - val_loss: 9.7597e-05 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.6801e-05 - accuracy: 1.0000 - val_loss: 9.6095e-05 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.5804e-05 - accuracy: 1.0000 - val_loss: 9.4617e-05 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.4837e-05 - accuracy: 1.0000 - val_loss: 9.3163e-05 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 6.3903e-05 - accuracy: 1.0000 - val_loss: 9.1733e-05 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.2981e-05 - accuracy: 1.0000 - val_loss: 9.0327e-05 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.2071e-05 - accuracy: 1.0000 - val_loss: 8.8920e-05 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.1180e-05 - accuracy: 1.0000 - val_loss: 8.7490e-05 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.0277e-05 - accuracy: 1.0000 - val_loss: 8.6179e-05 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.9436e-05 - accuracy: 1.0000 - val_loss: 8.4868e-05 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.8615e-05 - accuracy: 1.0000 - val_loss: 8.3533e-05 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.7762e-05 - accuracy: 1.0000 - val_loss: 8.2270e-05 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.6984e-05 - accuracy: 1.0000 - val_loss: 8.1054e-05 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.6174e-05 - accuracy: 1.0000 - val_loss: 7.9791e-05 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.5321e-05 - accuracy: 1.0000 - val_loss: 7.8575e-05 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.4531e-05 - accuracy: 1.0000 - val_loss: 7.7431e-05 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.3759e-05 - accuracy: 1.0000 - val_loss: 7.6287e-05 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.2988e-05 - accuracy: 1.0000 - val_loss: 7.5143e-05 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.2216e-05 - accuracy: 1.0000 - val_loss: 7.4284e-05 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.1595e-05 - accuracy: 1.0000 - val_loss: 7.3569e-05 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.1030e-05 - accuracy: 1.0000 - val_loss: 7.2902e-05 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.0529e-05 - accuracy: 1.0000 - val_loss: 7.2258e-05 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.0058e-05 - accuracy: 1.0000 - val_loss: 7.1567e-05 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.9544e-05 - accuracy: 1.0000 - val_loss: 7.0899e-05 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.9061e-05 - accuracy: 1.0000 - val_loss: 7.0232e-05 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.8577e-05 - accuracy: 1.0000 - val_loss: 6.9541e-05 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.8101e-05 - accuracy: 1.0000 - val_loss: 6.8873e-05 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.7674e-05 - accuracy: 1.0000 - val_loss: 6.8158e-05 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.7204e-05 - accuracy: 1.0000 - val_loss: 6.7443e-05 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6733e-05 - accuracy: 1.0000 - val_loss: 6.6775e-05 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.6307e-05 - accuracy: 1.0000 - val_loss: 6.6084e-05 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5867e-05 - accuracy: 1.0000 - val_loss: 6.5440e-05 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.5472e-05 - accuracy: 1.0000 - val_loss: 6.4749e-05 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.5033e-05 - accuracy: 1.0000 - val_loss: 6.4106e-05 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.4638e-05 - accuracy: 1.0000 - val_loss: 6.3438e-05 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.4211e-05 - accuracy: 1.0000 - val_loss: 6.2818e-05 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.3829e-05 - accuracy: 1.0000 - val_loss: 6.2199e-05 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.3446e-05 - accuracy: 1.0000 - val_loss: 6.1555e-05 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.3051e-05 - accuracy: 1.0000 - val_loss: 6.0959e-05 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.2643e-05 - accuracy: 1.0000 - val_loss: 6.0387e-05 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.2285e-05 - accuracy: 1.0000 - val_loss: 5.9815e-05 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.1909e-05 - accuracy: 1.0000 - val_loss: 5.9290e-05 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1558e-05 - accuracy: 1.0000 - val_loss: 5.8766e-05 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.1188e-05 - accuracy: 1.0000 - val_loss: 5.8265e-05 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.0849e-05 - accuracy: 1.0000 - val_loss: 5.7765e-05 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 2.7245e-05 - accuracy: 1.0000\n",
      "Test accuracy: 1.0\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe63e8d8670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Confusion Matrix:\n",
      "[[15  0]\n",
      " [ 0  1]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BUBBLE 5\n",
    "\n",
    "y_train5 = np.where(y_trainV != 5, 0, 1)\n",
    "y_test5 = np.where(y_testV != 5, 0, 1)\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define and compile the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_trainV.shape[1], X_trainV.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))  # Assuming you have 4 classes\n",
    "custom_optimizer = Adam(lr=0.01)\n",
    "model.compile(optimizer=custom_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_trainV, y_train5, epochs=200, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_testV, y_test5)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_testV)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate and print confusion matrix\n",
    "conf_mat = confusion_matrix(y_test5, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "# Print classification report\n",
    "class_report = classification_report(y_test5, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2727090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.3611 - accuracy: 0.8947 - val_loss: 12.1173 - val_accuracy: 0.8000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.3775 - accuracy: 0.8947 - val_loss: 5.2233 - val_accuracy: 0.8000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.7491 - accuracy: 0.8947 - val_loss: 0.4124 - val_accuracy: 0.8000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2629 - accuracy: 0.8947 - val_loss: 3.4317 - val_accuracy: 0.2000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8082 - accuracy: 0.1053 - val_loss: 0.8676 - val_accuracy: 0.2000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9186 - accuracy: 0.1053 - val_loss: 0.4763 - val_accuracy: 0.8000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3283 - accuracy: 0.8947 - val_loss: 0.6254 - val_accuracy: 0.8000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3508 - accuracy: 0.8947 - val_loss: 0.5247 - val_accuracy: 0.8000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3193 - accuracy: 0.8947 - val_loss: 0.4475 - val_accuracy: 0.8000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3406 - accuracy: 0.8947 - val_loss: 0.4612 - val_accuracy: 0.8000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2986 - accuracy: 0.8947 - val_loss: 0.5435 - val_accuracy: 0.8000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3092 - accuracy: 0.8947 - val_loss: 0.4248 - val_accuracy: 0.8000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2736 - accuracy: 0.8947 - val_loss: 0.3701 - val_accuracy: 0.8000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2656 - accuracy: 0.8947 - val_loss: 0.3628 - val_accuracy: 0.8000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2441 - accuracy: 0.8947 - val_loss: 0.3316 - val_accuracy: 0.8000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2218 - accuracy: 0.8947 - val_loss: 0.2961 - val_accuracy: 0.8000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1954 - accuracy: 0.8947 - val_loss: 0.2306 - val_accuracy: 0.8000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1695 - accuracy: 0.8947 - val_loss: 0.4322 - val_accuracy: 0.8000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2329 - accuracy: 0.8947 - val_loss: 0.1553 - val_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1321 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1073 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0924 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0687 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 9.8016e-04 - accuracy: 1.0000 - val_loss: 9.7472e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.9867e-04 - accuracy: 1.0000 - val_loss: 9.2186e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.5490e-04 - accuracy: 1.0000 - val_loss: 8.3263e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.9859e-04 - accuracy: 1.0000 - val_loss: 5.6495e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.7725e-04 - accuracy: 1.0000 - val_loss: 3.8367e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.5836e-04 - accuracy: 1.0000 - val_loss: 2.9645e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3798e-04 - accuracy: 1.0000 - val_loss: 2.7960e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.9044e-04 - accuracy: 1.0000 - val_loss: 3.0178e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.8298e-04 - accuracy: 1.0000 - val_loss: 3.3509e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.9103e-04 - accuracy: 1.0000 - val_loss: 3.5693e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.9768e-04 - accuracy: 1.0000 - val_loss: 3.5369e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.9355e-04 - accuracy: 1.0000 - val_loss: 3.2260e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7600e-04 - accuracy: 1.0000 - val_loss: 2.7279e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4935e-04 - accuracy: 1.0000 - val_loss: 2.1769e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2037e-04 - accuracy: 1.0000 - val_loss: 1.6755e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.4394e-05 - accuracy: 1.0000 - val_loss: 1.2769e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.4130e-05 - accuracy: 1.0000 - val_loss: 9.8520e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5.9796e-05 - accuracy: 1.0000 - val_loss: 7.8287e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.0407e-05 - accuracy: 1.0000 - val_loss: 6.5082e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.4907e-05 - accuracy: 1.0000 - val_loss: 5.6906e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.2185e-05 - accuracy: 1.0000 - val_loss: 5.2211e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.1351e-05 - accuracy: 1.0000 - val_loss: 4.9755e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1564e-05 - accuracy: 1.0000 - val_loss: 4.8539e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.2223e-05 - accuracy: 1.0000 - val_loss: 4.7848e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2819e-05 - accuracy: 1.0000 - val_loss: 4.7109e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.2882e-05 - accuracy: 1.0000 - val_loss: 4.6084e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.2342e-05 - accuracy: 1.0000 - val_loss: 4.4653e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.1119e-05 - accuracy: 1.0000 - val_loss: 4.2913e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.9318e-05 - accuracy: 1.0000 - val_loss: 4.0839e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7097e-05 - accuracy: 1.0000 - val_loss: 3.8837e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.4726e-05 - accuracy: 1.0000 - val_loss: 3.6882e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.2342e-05 - accuracy: 1.0000 - val_loss: 3.5189e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.0115e-05 - accuracy: 1.0000 - val_loss: 3.3830e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.8157e-05 - accuracy: 1.0000 - val_loss: 3.2829e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.6501e-05 - accuracy: 1.0000 - val_loss: 3.2138e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.5121e-05 - accuracy: 1.0000 - val_loss: 3.1852e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.4105e-05 - accuracy: 1.0000 - val_loss: 3.1851e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3389e-05 - accuracy: 1.0000 - val_loss: 3.2042e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2850e-05 - accuracy: 1.0000 - val_loss: 3.2447e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.2555e-05 - accuracy: 1.0000 - val_loss: 3.2876e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.2329e-05 - accuracy: 1.0000 - val_loss: 3.3377e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.2254e-05 - accuracy: 1.0000 - val_loss: 3.3806e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.2216e-05 - accuracy: 1.0000 - val_loss: 3.4164e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.2159e-05 - accuracy: 1.0000 - val_loss: 3.4450e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.2141e-05 - accuracy: 1.0000 - val_loss: 3.4545e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.2078e-05 - accuracy: 1.0000 - val_loss: 3.4569e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.1996e-05 - accuracy: 1.0000 - val_loss: 3.4402e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.1871e-05 - accuracy: 1.0000 - val_loss: 3.4092e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.1689e-05 - accuracy: 1.0000 - val_loss: 3.3687e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.1475e-05 - accuracy: 1.0000 - val_loss: 3.3138e-05 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.1225e-05 - accuracy: 1.0000 - val_loss: 3.2542e-05 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.0967e-05 - accuracy: 1.0000 - val_loss: 3.1899e-05 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0685e-05 - accuracy: 1.0000 - val_loss: 3.1255e-05 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.0440e-05 - accuracy: 1.0000 - val_loss: 3.0588e-05 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.0183e-05 - accuracy: 1.0000 - val_loss: 2.9944e-05 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9976e-05 - accuracy: 1.0000 - val_loss: 2.9396e-05 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.9801e-05 - accuracy: 1.0000 - val_loss: 2.8824e-05 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.9631e-05 - accuracy: 1.0000 - val_loss: 2.8323e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9481e-05 - accuracy: 1.0000 - val_loss: 2.7846e-05 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.9343e-05 - accuracy: 1.0000 - val_loss: 2.7465e-05 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.9255e-05 - accuracy: 1.0000 - val_loss: 2.7107e-05 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.9161e-05 - accuracy: 1.0000 - val_loss: 2.6821e-05 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.9123e-05 - accuracy: 1.0000 - val_loss: 2.6559e-05 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.9060e-05 - accuracy: 1.0000 - val_loss: 2.6321e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.9010e-05 - accuracy: 1.0000 - val_loss: 2.6177e-05 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8973e-05 - accuracy: 1.0000 - val_loss: 2.6034e-05 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.8935e-05 - accuracy: 1.0000 - val_loss: 2.5868e-05 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8866e-05 - accuracy: 1.0000 - val_loss: 2.5772e-05 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.8816e-05 - accuracy: 1.0000 - val_loss: 2.5677e-05 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8766e-05 - accuracy: 1.0000 - val_loss: 2.5605e-05 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8709e-05 - accuracy: 1.0000 - val_loss: 2.5558e-05 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8646e-05 - accuracy: 1.0000 - val_loss: 2.5486e-05 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.8571e-05 - accuracy: 1.0000 - val_loss: 2.5462e-05 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8502e-05 - accuracy: 1.0000 - val_loss: 2.5415e-05 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.8420e-05 - accuracy: 1.0000 - val_loss: 2.5438e-05 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.8377e-05 - accuracy: 1.0000 - val_loss: 2.5415e-05 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8270e-05 - accuracy: 1.0000 - val_loss: 2.5438e-05 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8226e-05 - accuracy: 1.0000 - val_loss: 2.5438e-05 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8151e-05 - accuracy: 1.0000 - val_loss: 2.5438e-05 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.8094e-05 - accuracy: 1.0000 - val_loss: 2.5438e-05 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.8038e-05 - accuracy: 1.0000 - val_loss: 2.5462e-05 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7994e-05 - accuracy: 1.0000 - val_loss: 2.5486e-05 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7950e-05 - accuracy: 1.0000 - val_loss: 2.5486e-05 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7893e-05 - accuracy: 1.0000 - val_loss: 2.5462e-05 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.7843e-05 - accuracy: 1.0000 - val_loss: 2.5438e-05 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7793e-05 - accuracy: 1.0000 - val_loss: 2.5438e-05 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7737e-05 - accuracy: 1.0000 - val_loss: 2.5415e-05 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7686e-05 - accuracy: 1.0000 - val_loss: 2.5391e-05 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7655e-05 - accuracy: 1.0000 - val_loss: 2.5319e-05 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7599e-05 - accuracy: 1.0000 - val_loss: 2.5272e-05 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.7555e-05 - accuracy: 1.0000 - val_loss: 2.5200e-05 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7498e-05 - accuracy: 1.0000 - val_loss: 2.5128e-05 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7461e-05 - accuracy: 1.0000 - val_loss: 2.5033e-05 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7410e-05 - accuracy: 1.0000 - val_loss: 2.4938e-05 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.7341e-05 - accuracy: 1.0000 - val_loss: 2.4842e-05 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.7291e-05 - accuracy: 1.0000 - val_loss: 2.4747e-05 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.7241e-05 - accuracy: 1.0000 - val_loss: 2.4652e-05 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7210e-05 - accuracy: 1.0000 - val_loss: 2.4556e-05 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.7159e-05 - accuracy: 1.0000 - val_loss: 2.4461e-05 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.7109e-05 - accuracy: 1.0000 - val_loss: 2.4342e-05 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.7046e-05 - accuracy: 1.0000 - val_loss: 2.4246e-05 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6996e-05 - accuracy: 1.0000 - val_loss: 2.4151e-05 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6946e-05 - accuracy: 1.0000 - val_loss: 2.4056e-05 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.6896e-05 - accuracy: 1.0000 - val_loss: 2.3960e-05 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6865e-05 - accuracy: 1.0000 - val_loss: 2.3865e-05 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6796e-05 - accuracy: 1.0000 - val_loss: 2.3793e-05 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6758e-05 - accuracy: 1.0000 - val_loss: 2.3698e-05 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6708e-05 - accuracy: 1.0000 - val_loss: 2.3650e-05 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.6683e-05 - accuracy: 1.0000 - val_loss: 2.3555e-05 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6614e-05 - accuracy: 1.0000 - val_loss: 2.3484e-05 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.6576e-05 - accuracy: 1.0000 - val_loss: 2.3412e-05 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6519e-05 - accuracy: 1.0000 - val_loss: 2.3340e-05 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6482e-05 - accuracy: 1.0000 - val_loss: 2.3293e-05 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6438e-05 - accuracy: 1.0000 - val_loss: 2.3197e-05 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.6369e-05 - accuracy: 1.0000 - val_loss: 2.3150e-05 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6344e-05 - accuracy: 1.0000 - val_loss: 2.3102e-05 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6281e-05 - accuracy: 1.0000 - val_loss: 2.3031e-05 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.6225e-05 - accuracy: 1.0000 - val_loss: 2.2959e-05 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6168e-05 - accuracy: 1.0000 - val_loss: 2.2911e-05 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6124e-05 - accuracy: 1.0000 - val_loss: 2.2840e-05 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6068e-05 - accuracy: 1.0000 - val_loss: 2.2768e-05 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.6011e-05 - accuracy: 1.0000 - val_loss: 2.2697e-05 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.5974e-05 - accuracy: 1.0000 - val_loss: 2.2649e-05 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5930e-05 - accuracy: 1.0000 - val_loss: 2.2601e-05 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5886e-05 - accuracy: 1.0000 - val_loss: 2.2554e-05 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.5842e-05 - accuracy: 1.0000 - val_loss: 2.2506e-05 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5798e-05 - accuracy: 1.0000 - val_loss: 2.2435e-05 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.5760e-05 - accuracy: 1.0000 - val_loss: 2.2387e-05 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.5716e-05 - accuracy: 1.0000 - val_loss: 2.2315e-05 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5660e-05 - accuracy: 1.0000 - val_loss: 2.2268e-05 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5616e-05 - accuracy: 1.0000 - val_loss: 2.2172e-05 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5566e-05 - accuracy: 1.0000 - val_loss: 2.2101e-05 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5509e-05 - accuracy: 1.0000 - val_loss: 2.2029e-05 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5472e-05 - accuracy: 1.0000 - val_loss: 2.1958e-05 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5415e-05 - accuracy: 1.0000 - val_loss: 2.1934e-05 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5384e-05 - accuracy: 1.0000 - val_loss: 2.1862e-05 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5346e-05 - accuracy: 1.0000 - val_loss: 2.1791e-05 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5290e-05 - accuracy: 1.0000 - val_loss: 2.1743e-05 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5265e-05 - accuracy: 1.0000 - val_loss: 2.1648e-05 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5196e-05 - accuracy: 1.0000 - val_loss: 2.1576e-05 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5139e-05 - accuracy: 1.0000 - val_loss: 2.1505e-05 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5083e-05 - accuracy: 1.0000 - val_loss: 2.1457e-05 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5058e-05 - accuracy: 1.0000 - val_loss: 2.1386e-05 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5001e-05 - accuracy: 1.0000 - val_loss: 2.1314e-05 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4964e-05 - accuracy: 1.0000 - val_loss: 2.1266e-05 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4920e-05 - accuracy: 1.0000 - val_loss: 2.1195e-05 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4882e-05 - accuracy: 1.0000 - val_loss: 2.1123e-05 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4826e-05 - accuracy: 1.0000 - val_loss: 2.1076e-05 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4800e-05 - accuracy: 1.0000 - val_loss: 2.1004e-05 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4744e-05 - accuracy: 1.0000 - val_loss: 2.0956e-05 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4719e-05 - accuracy: 1.0000 - val_loss: 2.0885e-05 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4662e-05 - accuracy: 1.0000 - val_loss: 2.0813e-05 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4625e-05 - accuracy: 1.0000 - val_loss: 2.0766e-05 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.4581e-05 - accuracy: 1.0000 - val_loss: 2.0694e-05 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4524e-05 - accuracy: 1.0000 - val_loss: 2.0623e-05 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4487e-05 - accuracy: 1.0000 - val_loss: 2.0551e-05 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4430e-05 - accuracy: 1.0000 - val_loss: 2.0480e-05 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4393e-05 - accuracy: 1.0000 - val_loss: 2.0456e-05 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4361e-05 - accuracy: 1.0000 - val_loss: 2.0384e-05 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4305e-05 - accuracy: 1.0000 - val_loss: 2.0337e-05 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4280e-05 - accuracy: 1.0000 - val_loss: 2.0265e-05 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4223e-05 - accuracy: 1.0000 - val_loss: 2.0194e-05 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4186e-05 - accuracy: 1.0000 - val_loss: 2.0146e-05 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4142e-05 - accuracy: 1.0000 - val_loss: 2.0098e-05 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4098e-05 - accuracy: 1.0000 - val_loss: 2.0050e-05 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 8.7283e-04 - accuracy: 1.0000\n",
      "Test accuracy: 1.0\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe63eb130d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Confusion Matrix:\n",
      "[[15  0]\n",
      " [ 0  1]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BUBBLE 6\n",
    "\n",
    "y_train6 = np.where(y_trainV != 6, 0, 1)\n",
    "y_test6 = np.where(y_testV != 6, 0, 1)\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define and compile the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_trainV.shape[1], X_trainV.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))  # Assuming you have 4 classes\n",
    "custom_optimizer = Adam(lr=0.01)\n",
    "model.compile(optimizer=custom_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_trainV, y_train6, epochs=200, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_testV, y_test6)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_testV)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate and print confusion matrix\n",
    "conf_mat = confusion_matrix(y_test6, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "# Print classification report\n",
    "class_report = classification_report(y_test6, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c8855e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewweiner/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 470ms/step - loss: 0.6297 - accuracy: 0.8947 - val_loss: 6.8046 - val_accuracy: 0.8000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.5814 - accuracy: 0.8947 - val_loss: 4.7285 - val_accuracy: 0.8000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.4887 - accuracy: 0.8947 - val_loss: 2.2976 - val_accuracy: 0.8000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2093 - accuracy: 0.8947 - val_loss: 0.5936 - val_accuracy: 0.8000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3238 - accuracy: 0.8947 - val_loss: 2.0979 - val_accuracy: 0.2000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.3242 - accuracy: 0.1053 - val_loss: 0.8527 - val_accuracy: 0.2000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8900 - accuracy: 0.1053 - val_loss: 0.5771 - val_accuracy: 0.8000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5346 - accuracy: 0.8947 - val_loss: 0.5182 - val_accuracy: 0.8000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4406 - accuracy: 0.8947 - val_loss: 0.4863 - val_accuracy: 0.8000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3803 - accuracy: 0.8947 - val_loss: 0.5262 - val_accuracy: 0.8000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3229 - accuracy: 0.8947 - val_loss: 0.6632 - val_accuracy: 0.8000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3646 - accuracy: 0.8947 - val_loss: 0.6197 - val_accuracy: 0.8000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3446 - accuracy: 0.8947 - val_loss: 0.5198 - val_accuracy: 0.8000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3101 - accuracy: 0.8947 - val_loss: 0.4780 - val_accuracy: 0.8000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3057 - accuracy: 0.8947 - val_loss: 0.4615 - val_accuracy: 0.8000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3061 - accuracy: 0.8947 - val_loss: 0.4505 - val_accuracy: 0.8000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2981 - accuracy: 0.8947 - val_loss: 0.4492 - val_accuracy: 0.8000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2851 - accuracy: 0.8947 - val_loss: 0.4555 - val_accuracy: 0.8000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2764 - accuracy: 0.8947 - val_loss: 0.4478 - val_accuracy: 0.8000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2669 - accuracy: 0.8947 - val_loss: 0.4145 - val_accuracy: 0.8000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2510 - accuracy: 0.8947 - val_loss: 0.3700 - val_accuracy: 0.8000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2332 - accuracy: 0.8947 - val_loss: 0.3330 - val_accuracy: 0.8000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2146 - accuracy: 0.8947 - val_loss: 0.3031 - val_accuracy: 0.8000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1907 - accuracy: 0.8947 - val_loss: 0.2736 - val_accuracy: 0.8000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1674 - accuracy: 0.8947 - val_loss: 0.2265 - val_accuracy: 0.8000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1391 - accuracy: 0.8947 - val_loss: 0.1713 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1083 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0964 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.8000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0879 - accuracy: 0.8947 - val_loss: 0.0919 - val_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.0557 - val_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 9.9210e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.0214e-04 - accuracy: 1.0000 - val_loss: 9.9122e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5.5943e-04 - accuracy: 1.0000 - val_loss: 6.5097e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.6496e-04 - accuracy: 1.0000 - val_loss: 4.4616e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.4741e-04 - accuracy: 1.0000 - val_loss: 3.4253e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.8739e-04 - accuracy: 1.0000 - val_loss: 2.9840e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6121e-04 - accuracy: 1.0000 - val_loss: 2.8254e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5128e-04 - accuracy: 1.0000 - val_loss: 2.7563e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4675e-04 - accuracy: 1.0000 - val_loss: 2.6817e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4233e-04 - accuracy: 1.0000 - val_loss: 2.5459e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3490e-04 - accuracy: 1.0000 - val_loss: 2.3398e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2388e-04 - accuracy: 1.0000 - val_loss: 2.0916e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1073e-04 - accuracy: 1.0000 - val_loss: 1.8056e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.5631e-05 - accuracy: 1.0000 - val_loss: 1.5168e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.0434e-05 - accuracy: 1.0000 - val_loss: 1.2526e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 6.6527e-05 - accuracy: 1.0000 - val_loss: 1.0281e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.4750e-05 - accuracy: 1.0000 - val_loss: 8.4816e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.5337e-05 - accuracy: 1.0000 - val_loss: 7.0993e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8118e-05 - accuracy: 1.0000 - val_loss: 6.0720e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.2786e-05 - accuracy: 1.0000 - val_loss: 5.3307e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.8960e-05 - accuracy: 1.0000 - val_loss: 4.8158e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.6344e-05 - accuracy: 1.0000 - val_loss: 4.4725e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 2.4631e-05 - accuracy: 1.0000 - val_loss: 4.2484e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.3565e-05 - accuracy: 1.0000 - val_loss: 4.1126e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.2944e-05 - accuracy: 1.0000 - val_loss: 4.0315e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.2611e-05 - accuracy: 1.0000 - val_loss: 3.9790e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.2411e-05 - accuracy: 1.0000 - val_loss: 3.9433e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.2279e-05 - accuracy: 1.0000 - val_loss: 3.9075e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.2147e-05 - accuracy: 1.0000 - val_loss: 3.8622e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.1927e-05 - accuracy: 1.0000 - val_loss: 3.8002e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.1620e-05 - accuracy: 1.0000 - val_loss: 3.7263e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2.1212e-05 - accuracy: 1.0000 - val_loss: 3.6334e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.0704e-05 - accuracy: 1.0000 - val_loss: 3.5285e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.0114e-05 - accuracy: 1.0000 - val_loss: 3.4140e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.9456e-05 - accuracy: 1.0000 - val_loss: 3.2948e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8772e-05 - accuracy: 1.0000 - val_loss: 3.1780e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.8100e-05 - accuracy: 1.0000 - val_loss: 3.0612e-05 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.7410e-05 - accuracy: 1.0000 - val_loss: 2.9492e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.6745e-05 - accuracy: 1.0000 - val_loss: 2.8490e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6162e-05 - accuracy: 1.0000 - val_loss: 2.7584e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.5610e-05 - accuracy: 1.0000 - val_loss: 2.6750e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.5114e-05 - accuracy: 1.0000 - val_loss: 2.6059e-05 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4675e-05 - accuracy: 1.0000 - val_loss: 2.5462e-05 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4324e-05 - accuracy: 1.0000 - val_loss: 2.4986e-05 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.4016e-05 - accuracy: 1.0000 - val_loss: 2.4580e-05 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3728e-05 - accuracy: 1.0000 - val_loss: 2.4270e-05 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.3527e-05 - accuracy: 1.0000 - val_loss: 2.4008e-05 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3351e-05 - accuracy: 1.0000 - val_loss: 2.3817e-05 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3232e-05 - accuracy: 1.0000 - val_loss: 2.3674e-05 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.3119e-05 - accuracy: 1.0000 - val_loss: 2.3555e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.3037e-05 - accuracy: 1.0000 - val_loss: 2.3484e-05 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2981e-05 - accuracy: 1.0000 - val_loss: 2.3388e-05 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2912e-05 - accuracy: 1.0000 - val_loss: 2.3317e-05 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2855e-05 - accuracy: 1.0000 - val_loss: 2.3221e-05 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2786e-05 - accuracy: 1.0000 - val_loss: 2.3150e-05 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.2749e-05 - accuracy: 1.0000 - val_loss: 2.3054e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.2699e-05 - accuracy: 1.0000 - val_loss: 2.2935e-05 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2617e-05 - accuracy: 1.0000 - val_loss: 2.2792e-05 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2542e-05 - accuracy: 1.0000 - val_loss: 2.2649e-05 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.2466e-05 - accuracy: 1.0000 - val_loss: 2.2506e-05 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2391e-05 - accuracy: 1.0000 - val_loss: 2.2363e-05 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2316e-05 - accuracy: 1.0000 - val_loss: 2.2244e-05 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2253e-05 - accuracy: 1.0000 - val_loss: 2.2077e-05 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2184e-05 - accuracy: 1.0000 - val_loss: 2.1934e-05 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.2109e-05 - accuracy: 1.0000 - val_loss: 2.1743e-05 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2008e-05 - accuracy: 1.0000 - val_loss: 2.1600e-05 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1933e-05 - accuracy: 1.0000 - val_loss: 2.1433e-05 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1864e-05 - accuracy: 1.0000 - val_loss: 2.1290e-05 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1789e-05 - accuracy: 1.0000 - val_loss: 2.1147e-05 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1732e-05 - accuracy: 1.0000 - val_loss: 2.1004e-05 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.1657e-05 - accuracy: 1.0000 - val_loss: 2.0861e-05 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1582e-05 - accuracy: 1.0000 - val_loss: 2.0742e-05 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1538e-05 - accuracy: 1.0000 - val_loss: 2.0647e-05 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1488e-05 - accuracy: 1.0000 - val_loss: 2.0504e-05 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1412e-05 - accuracy: 1.0000 - val_loss: 2.0408e-05 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1381e-05 - accuracy: 1.0000 - val_loss: 2.0313e-05 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1331e-05 - accuracy: 1.0000 - val_loss: 2.0194e-05 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1268e-05 - accuracy: 1.0000 - val_loss: 2.0098e-05 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.1218e-05 - accuracy: 1.0000 - val_loss: 2.0027e-05 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.1199e-05 - accuracy: 1.0000 - val_loss: 1.9931e-05 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1149e-05 - accuracy: 1.0000 - val_loss: 1.9860e-05 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.1111e-05 - accuracy: 1.0000 - val_loss: 1.9741e-05 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1049e-05 - accuracy: 1.0000 - val_loss: 1.9669e-05 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1011e-05 - accuracy: 1.0000 - val_loss: 1.9598e-05 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0973e-05 - accuracy: 1.0000 - val_loss: 1.9502e-05 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0923e-05 - accuracy: 1.0000 - val_loss: 1.9407e-05 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0873e-05 - accuracy: 1.0000 - val_loss: 1.9335e-05 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0835e-05 - accuracy: 1.0000 - val_loss: 1.9264e-05 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0798e-05 - accuracy: 1.0000 - val_loss: 1.9192e-05 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0760e-05 - accuracy: 1.0000 - val_loss: 1.9097e-05 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.0710e-05 - accuracy: 1.0000 - val_loss: 1.9002e-05 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0660e-05 - accuracy: 1.0000 - val_loss: 1.8930e-05 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0622e-05 - accuracy: 1.0000 - val_loss: 1.8859e-05 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0566e-05 - accuracy: 1.0000 - val_loss: 1.8763e-05 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0515e-05 - accuracy: 1.0000 - val_loss: 1.8692e-05 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0478e-05 - accuracy: 1.0000 - val_loss: 1.8620e-05 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0440e-05 - accuracy: 1.0000 - val_loss: 1.8572e-05 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0415e-05 - accuracy: 1.0000 - val_loss: 1.8477e-05 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0365e-05 - accuracy: 1.0000 - val_loss: 1.8429e-05 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0340e-05 - accuracy: 1.0000 - val_loss: 1.8334e-05 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.0271e-05 - accuracy: 1.0000 - val_loss: 1.8263e-05 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0233e-05 - accuracy: 1.0000 - val_loss: 1.8191e-05 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0195e-05 - accuracy: 1.0000 - val_loss: 1.8119e-05 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0158e-05 - accuracy: 1.0000 - val_loss: 1.8048e-05 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.0120e-05 - accuracy: 1.0000 - val_loss: 1.7976e-05 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.0082e-05 - accuracy: 1.0000 - val_loss: 1.7905e-05 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0045e-05 - accuracy: 1.0000 - val_loss: 1.7857e-05 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0020e-05 - accuracy: 1.0000 - val_loss: 1.7762e-05 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.9695e-06 - accuracy: 1.0000 - val_loss: 1.7714e-05 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.9256e-06 - accuracy: 1.0000 - val_loss: 1.7643e-05 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.8879e-06 - accuracy: 1.0000 - val_loss: 1.7547e-05 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.8377e-06 - accuracy: 1.0000 - val_loss: 1.7500e-05 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.8126e-06 - accuracy: 1.0000 - val_loss: 1.7404e-05 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.7624e-06 - accuracy: 1.0000 - val_loss: 1.7357e-05 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.7374e-06 - accuracy: 1.0000 - val_loss: 1.7285e-05 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 9.6997e-06 - accuracy: 1.0000 - val_loss: 1.7214e-05 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 9.6621e-06 - accuracy: 1.0000 - val_loss: 1.7142e-05 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 9.6244e-06 - accuracy: 1.0000 - val_loss: 1.7070e-05 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.5868e-06 - accuracy: 1.0000 - val_loss: 1.7023e-05 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.5617e-06 - accuracy: 1.0000 - val_loss: 1.6951e-05 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 9.5240e-06 - accuracy: 1.0000 - val_loss: 1.6880e-05 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.4864e-06 - accuracy: 1.0000 - val_loss: 1.6784e-05 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.4362e-06 - accuracy: 1.0000 - val_loss: 1.6737e-05 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.4111e-06 - accuracy: 1.0000 - val_loss: 1.6665e-05 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.3735e-06 - accuracy: 1.0000 - val_loss: 1.6594e-05 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.3358e-06 - accuracy: 1.0000 - val_loss: 1.6522e-05 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.2982e-06 - accuracy: 1.0000 - val_loss: 1.6474e-05 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 9.2731e-06 - accuracy: 1.0000 - val_loss: 1.6403e-05 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 9.2354e-06 - accuracy: 1.0000 - val_loss: 1.6308e-05 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.1852e-06 - accuracy: 1.0000 - val_loss: 1.6236e-05 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.1476e-06 - accuracy: 1.0000 - val_loss: 1.6188e-05 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.1225e-06 - accuracy: 1.0000 - val_loss: 1.6117e-05 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.0849e-06 - accuracy: 1.0000 - val_loss: 1.6069e-05 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 9.0598e-06 - accuracy: 1.0000 - val_loss: 1.5998e-05 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.0221e-06 - accuracy: 1.0000 - val_loss: 1.5926e-05 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.9845e-06 - accuracy: 1.0000 - val_loss: 1.5855e-05 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 8.9468e-06 - accuracy: 1.0000 - val_loss: 1.5807e-05 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.9217e-06 - accuracy: 1.0000 - val_loss: 1.5735e-05 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.8841e-06 - accuracy: 1.0000 - val_loss: 1.5688e-05 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.8402e-06 - accuracy: 1.0000 - val_loss: 1.5592e-05 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.7900e-06 - accuracy: 1.0000 - val_loss: 1.5545e-05 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 8.7649e-06 - accuracy: 1.0000 - val_loss: 1.5497e-05 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.7398e-06 - accuracy: 1.0000 - val_loss: 1.5425e-05 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 8.7021e-06 - accuracy: 1.0000 - val_loss: 1.5378e-05 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 8.6771e-06 - accuracy: 1.0000 - val_loss: 1.5306e-05 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 8.6394e-06 - accuracy: 1.0000 - val_loss: 1.5259e-05 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.6143e-06 - accuracy: 1.0000 - val_loss: 1.5187e-05 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.5767e-06 - accuracy: 1.0000 - val_loss: 1.5139e-05 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.5516e-06 - accuracy: 1.0000 - val_loss: 1.5092e-05 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.5265e-06 - accuracy: 1.0000 - val_loss: 1.5020e-05 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.4888e-06 - accuracy: 1.0000 - val_loss: 1.4949e-05 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.4512e-06 - accuracy: 1.0000 - val_loss: 1.4901e-05 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.4261e-06 - accuracy: 1.0000 - val_loss: 1.4853e-05 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.4010e-06 - accuracy: 1.0000 - val_loss: 1.4806e-05 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.3759e-06 - accuracy: 1.0000 - val_loss: 1.4734e-05 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.3383e-06 - accuracy: 1.0000 - val_loss: 1.4663e-05 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.3006e-06 - accuracy: 1.0000 - val_loss: 1.4615e-05 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.3143e-04 - accuracy: 1.0000\n",
      "Test accuracy: 1.0\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Confusion Matrix:\n",
      "[[14  0]\n",
      " [ 0  2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BUBBLE 7\n",
    "\n",
    "y_train7 = np.where(y_trainV != 7, 0, 1)\n",
    "y_test7 = np.where(y_testV != 7, 0, 1)\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define and compile the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_trainV.shape[1], X_trainV.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))  # Assuming you have 4 classes\n",
    "custom_optimizer = Adam(lr=0.01)\n",
    "model.compile(optimizer=custom_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_trainV, y_train7, epochs=200, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_testV, y_test7)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_testV)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate and print confusion matrix\n",
    "conf_mat = confusion_matrix(y_test7, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "# Print classification report\n",
    "class_report = classification_report(y_test7, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fee75199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthewweiner/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 471ms/step - loss: 1.1029 - accuracy: 0.1053 - val_loss: 8.2863 - val_accuracy: 0.8000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.3612 - accuracy: 0.8947 - val_loss: 6.3989 - val_accuracy: 0.8000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.3678 - accuracy: 0.8947 - val_loss: 2.9853 - val_accuracy: 0.8000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 1.5712 - accuracy: 0.8947 - val_loss: 0.7184 - val_accuracy: 0.4000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7333 - accuracy: 0.2105 - val_loss: 1.1735 - val_accuracy: 0.8000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6189 - accuracy: 0.8947 - val_loss: 1.5682 - val_accuracy: 0.8000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8255 - accuracy: 0.8947 - val_loss: 1.4368 - val_accuracy: 0.8000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7565 - accuracy: 0.8947 - val_loss: 1.0011 - val_accuracy: 0.8000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5299 - accuracy: 0.8947 - val_loss: 0.5359 - val_accuracy: 0.8000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3291 - accuracy: 0.8947 - val_loss: 0.5693 - val_accuracy: 0.8000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5302 - accuracy: 0.8947 - val_loss: 0.4972 - val_accuracy: 0.8000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4133 - accuracy: 0.8947 - val_loss: 0.5111 - val_accuracy: 0.8000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3227 - accuracy: 0.8947 - val_loss: 0.6215 - val_accuracy: 0.8000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3493 - accuracy: 0.8947 - val_loss: 0.6854 - val_accuracy: 0.8000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3755 - accuracy: 0.8947 - val_loss: 0.6754 - val_accuracy: 0.8000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3708 - accuracy: 0.8947 - val_loss: 0.6164 - val_accuracy: 0.8000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3460 - accuracy: 0.8947 - val_loss: 0.5448 - val_accuracy: 0.8000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3222 - accuracy: 0.8947 - val_loss: 0.4901 - val_accuracy: 0.8000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3153 - accuracy: 0.8947 - val_loss: 0.4627 - val_accuracy: 0.8000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3246 - accuracy: 0.8947 - val_loss: 0.4549 - val_accuracy: 0.8000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3348 - accuracy: 0.8947 - val_loss: 0.4502 - val_accuracy: 0.8000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3307 - accuracy: 0.8947 - val_loss: 0.4474 - val_accuracy: 0.8000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3166 - accuracy: 0.8947 - val_loss: 0.4480 - val_accuracy: 0.8000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3049 - accuracy: 0.8947 - val_loss: 0.4692 - val_accuracy: 0.8000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2967 - accuracy: 0.8947 - val_loss: 0.4877 - val_accuracy: 0.8000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2957 - accuracy: 0.8947 - val_loss: 0.4590 - val_accuracy: 0.8000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2847 - accuracy: 0.8947 - val_loss: 0.4640 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4699 - accuracy: 1.0000 - val_loss: 0.5398 - val_accuracy: 0.8000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3055 - accuracy: 0.8947 - val_loss: 0.6786 - val_accuracy: 0.8000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3671 - accuracy: 0.8947 - val_loss: 0.6914 - val_accuracy: 0.8000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3734 - accuracy: 0.8947 - val_loss: 0.6320 - val_accuracy: 0.8000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3461 - accuracy: 0.8947 - val_loss: 0.4179 - val_accuracy: 0.8000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2773 - accuracy: 0.8947 - val_loss: 0.5477 - val_accuracy: 0.8000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6491 - accuracy: 0.7368 - val_loss: 0.4698 - val_accuracy: 0.8000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2862 - accuracy: 0.8947 - val_loss: 0.7300 - val_accuracy: 0.8000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3927 - accuracy: 0.8947 - val_loss: 0.8311 - val_accuracy: 0.8000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4425 - accuracy: 0.8947 - val_loss: 0.7735 - val_accuracy: 0.8000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4140 - accuracy: 0.8947 - val_loss: 0.6947 - val_accuracy: 0.8000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3764 - accuracy: 0.8947 - val_loss: 0.5836 - val_accuracy: 0.8000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3280 - accuracy: 0.8947 - val_loss: 0.4901 - val_accuracy: 0.8000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2992 - accuracy: 0.8947 - val_loss: 0.4337 - val_accuracy: 0.8000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2989 - accuracy: 0.8947 - val_loss: 0.4147 - val_accuracy: 0.8000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3190 - accuracy: 0.8947 - val_loss: 0.4125 - val_accuracy: 0.8000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3391 - accuracy: 0.8947 - val_loss: 0.4117 - val_accuracy: 0.8000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3468 - accuracy: 0.8947 - val_loss: 0.4055 - val_accuracy: 0.8000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3376 - accuracy: 0.8947 - val_loss: 0.3986 - val_accuracy: 0.8000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3142 - accuracy: 0.8947 - val_loss: 0.4011 - val_accuracy: 0.8000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2899 - accuracy: 0.8947 - val_loss: 0.4195 - val_accuracy: 0.8000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2758 - accuracy: 0.8947 - val_loss: 0.4528 - val_accuracy: 0.8000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2761 - accuracy: 0.8947 - val_loss: 0.4834 - val_accuracy: 0.8000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2830 - accuracy: 0.8947 - val_loss: 0.4953 - val_accuracy: 0.8000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2856 - accuracy: 0.8947 - val_loss: 0.4832 - val_accuracy: 0.8000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2792 - accuracy: 0.8947 - val_loss: 0.4562 - val_accuracy: 0.8000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2682 - accuracy: 0.8947 - val_loss: 0.4210 - val_accuracy: 0.8000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2557 - accuracy: 0.8947 - val_loss: 0.3882 - val_accuracy: 0.8000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2464 - accuracy: 0.8947 - val_loss: 0.3632 - val_accuracy: 0.8000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2413 - accuracy: 0.8947 - val_loss: 0.3453 - val_accuracy: 0.8000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2398 - accuracy: 0.8947 - val_loss: 0.3339 - val_accuracy: 0.8000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2387 - accuracy: 0.8947 - val_loss: 0.3259 - val_accuracy: 0.8000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2345 - accuracy: 0.8947 - val_loss: 0.3200 - val_accuracy: 0.8000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2258 - accuracy: 0.8947 - val_loss: 0.3192 - val_accuracy: 0.8000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2178 - accuracy: 0.8947 - val_loss: 0.3201 - val_accuracy: 0.8000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2115 - accuracy: 0.8947 - val_loss: 0.3164 - val_accuracy: 0.8000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2057 - accuracy: 0.8947 - val_loss: 0.3073 - val_accuracy: 0.8000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1997 - accuracy: 0.8947 - val_loss: 0.2964 - val_accuracy: 0.8000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1945 - accuracy: 0.8947 - val_loss: 0.2814 - val_accuracy: 0.8000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1885 - accuracy: 0.8947 - val_loss: 0.2694 - val_accuracy: 0.8000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1835 - accuracy: 0.8947 - val_loss: 0.2534 - val_accuracy: 0.8000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1795 - accuracy: 0.8947 - val_loss: 0.2367 - val_accuracy: 0.8000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1749 - accuracy: 0.8947 - val_loss: 0.2216 - val_accuracy: 0.8000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1680 - accuracy: 0.8947 - val_loss: 0.2153 - val_accuracy: 0.8000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1634 - accuracy: 0.8947 - val_loss: 0.2074 - val_accuracy: 0.8000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1586 - accuracy: 0.8947 - val_loss: 0.1970 - val_accuracy: 0.8000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1534 - accuracy: 0.8947 - val_loss: 0.1856 - val_accuracy: 0.8000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1481 - accuracy: 0.8947 - val_loss: 0.1760 - val_accuracy: 0.8000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1426 - accuracy: 0.8947 - val_loss: 0.1691 - val_accuracy: 0.8000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1372 - accuracy: 0.8947 - val_loss: 0.1633 - val_accuracy: 0.8000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1321 - accuracy: 0.8947 - val_loss: 0.1588 - val_accuracy: 0.8000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1273 - accuracy: 0.8947 - val_loss: 0.1529 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1226 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1175 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1131 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1079 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1031 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0982 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0940 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0895 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0853 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0776 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0740 - accuracy: 1.0000 - val_loss: 0.0728 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.0635 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0670 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.8031e-04 - accuracy: 1.0000\n",
      "Test accuracy: 1.0\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Confusion Matrix:\n",
      "[[16]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BUBBLE 7\n",
    "\n",
    "y_train8 = np.where(y_trainV != 8, 0, 1)\n",
    "y_test8 = np.where(y_testV != 8, 0, 0)\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define and compile the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_trainV.shape[1], X_trainV.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))  # Assuming you have 4 classes\n",
    "custom_optimizer = Adam(lr=0.01)\n",
    "model.compile(optimizer=custom_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_trainV, y_train8, epochs=200, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_testV, y_test8)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_testV)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate and print confusion matrix\n",
    "conf_mat = confusion_matrix(y_test8, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mat)\n",
    "\n",
    "# Print classification report\n",
    "class_report = classification_report(y_test8, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd15747f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# Save the plot to a file\n",
    "plot_model(model, to_file='cnn_model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Display the plot\n",
    "img = plt.imread('cnn_model.png')\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d2ca6a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dt/thmkdngd4pz6fncyw9thzyjw0000gn/T/ipykernel_64648/2109636262.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Create a figure of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvisualkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayered_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# display using your system viewer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mvisualkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayered_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output.png'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# write to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvisualkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayered_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# write and show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/visualkeras/layered.py\u001b[0m in \u001b[0;36mlayered_view\u001b[0;34m(model, to_file, min_z, min_xy, max_z, max_xy, scale_z, scale_xy, type_ignore, index_ignore, color_map, one_dim_orientation, background_fill, draw_volume, padding, spacing, draw_funnel, shade_step, legend, font, font_color)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale_xy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_xy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale_xy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_xy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mone_dim_orientation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "import visualkeras\n",
    "# Create a figure of the model\n",
    "visualkeras.layered_view(model).show() # display using your system viewer\n",
    "visualkeras.layered_view(model, to_file='output.png') # write to disk\n",
    "visualkeras.layered_view(model, to_file='output.png').show() # write and show\n",
    "\n",
    "visualkeras.layered_view(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada6a0b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
